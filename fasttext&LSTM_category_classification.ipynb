{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seungmanchoi/category_classification/blob/main/fasttext%26LSTM_category_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxQypQd1cNyz",
        "outputId": "cbe62903-03ed-4dae-91ed-c9f2c7e9d7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (71.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.26.4)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=4296185 sha256=aed64460bbde1818535266cfc90ab36b743def9c5322a9bbc797ac215fa9884b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import pandas as pd\n",
        "import re\n",
        "import sys\n",
        "import os\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "from tokenizers import normalizers\n",
        "from tokenizers.normalizers import NFKC\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "47_USN4EcRWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 설정\n",
        "epoch_count = 10\n",
        "word_ngrams = 3\n",
        "learning_rate = 0.1\n",
        "\n",
        "# 학습 데이터 경로\n",
        "train_data = '/content/drive/MyDrive/Colab Notebooks/item_category_classification/product_category_from_fullset_train_cleaned_filtered_tokenized.tsv'\n",
        "\n",
        "# tqdm을 사용한 학습 진행 표시\n",
        "for epoch in tqdm(range(1, epoch_count + 1)):\n",
        "    # 각 epoch에서 모델을 학습\n",
        "    model = fasttext.train_supervised(train_data, wordNgrams=word_ngrams, epoch=epoch, lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5kBCZqcYRO0",
        "outputId": "14c69824-b88a-4d12-8afd-2a4f08754531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [47:28<00:00, 284.81s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 마지막 모델 저장 (필요할 경우)\n",
        "model.save_model('/content/drive/MyDrive/Colab Notebooks/item_category_classification/tokenized_product_category_from_fullset_model_epoch10.bin')"
      ],
      "metadata": {
        "id": "KhpG-SgVpPle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. BPE 토크나이저 생성\n",
        "tokenizer = Tokenizer(BPE())\n",
        "tokenizer.normalizer = normalizers.Sequence([NFKC()])\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "# 2. BPE 트레이너 설정\n",
        "trainer = BpeTrainer(special_tokens=[\"<unk>\"], vocab_size=30000)\n",
        "\n",
        "# 3. 학습 데이터로 BPE 학습\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/item_category_classification/'\n",
        "files = [os.path.join(path, file_name) for file_name in os.listdir(path) if file_name.endswith('.tsv')]\n",
        "\n",
        "tokenizer.train(files, trainer)"
      ],
      "metadata": {
        "id": "mg0Ev1y4FLuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bpe_tokenize(text):\n",
        "    # BPE 토크나이징 수행\n",
        "    output = tokenizer.encode(text)\n",
        "    # 공백으로 구분된 토큰을 반환\n",
        "    return ' '.join(output.tokens)"
      ],
      "metadata": {
        "id": "qN1DLWINGKb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_predictions():\n",
        "    print('\\n분류할 상품명을 입력하세요 (종료하려면 Ctrl+Z 입력): ', file=sys.stderr)\n",
        "    while True:\n",
        "        try:\n",
        "            query = input().rstrip()\n",
        "            if not query:\n",
        "                break  # Exit if input is empty\n",
        "\n",
        "            tokenized_query = bpe_tokenize(query)\n",
        "            print(f'Tokenized query: {tokenized_query}')\n",
        "\n",
        "            result = model.predict(tokenized_query)\n",
        "\n",
        "            if result:\n",
        "                print(result)\n",
        "                print()\n",
        "            else:\n",
        "                print('\\n결과가 없습니다.')\n",
        "\n",
        "        except EOFError:\n",
        "            # Ctrl+Z가 입력되면 EOFError 발생\n",
        "            print(\"\\n입력이 종료되었습니다.\")\n",
        "            break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred: {e}\")\n",
        "            break"
      ],
      "metadata": {
        "id": "LJ8QtVvnE03o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_predictions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rj63a8PLHnXq",
        "outputId": "7068f311-01c4-439c-c90e-17ec6c54f39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "분류할 상품명을 입력하세요 (종료하려면 Ctrl+Z 입력): \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "앙고라오버핏가디건\n",
            "Tokenized query: 앙고라 오버핏 가디건\n",
            "(('__label__의류_여성아우터_가디건',), array([0.63917112]))\n",
            "\n",
            "오 대박\n",
            "Tokenized query: 오 대박\n",
            "(('__label__아동복_상의_티셔츠',), array([0.45340559]))\n",
            "\n",
            "이제 좀 잘 나오는구만\n",
            "Tokenized query: 이 제 좀 잘 나오는 구 만\n",
            "(('__label__악세사리_귀걸이_스터드',), array([0.03288327]))\n",
            "\n",
            "누나가만들어준예쁜귀걸이\n",
            "Tokenized query: 누 나가 만들 어 준 예쁜 귀걸이\n",
            "(('__label__악세사리_귀걸이_기타',), array([0.6898616]))\n",
            "\n",
            "내가만든은침피어싱\n",
            "Tokenized query: 내가 만 든 은침 피어싱\n",
            "(('__label__악세사리_피어싱_써지컬',), array([0.48618466]))\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/item_category_classification/product_category_from_fullset_test_cleaned_filtered_tokenized.tsv\", sep =\"\\t\")\n",
        "\n",
        "test_df.columns = ['category', 'product_name']\n",
        "\n",
        "def clean_label(label):\n",
        "    # 정규 표현식을 사용해 문자, 숫자, _만 남김\n",
        "    return re.sub(r\"^\\('([^']*)',\\)$\", r'\\1', label)\n",
        "\n",
        "predictions = []\n",
        "for line in test_df['product_name']:\n",
        "    pred_label = model.predict(line)[0]  # 튜플의 첫 번째 요소 가져오기\n",
        "    pred_label_str = str(pred_label)\n",
        "    clean_pred_label = clean_label(pred_label_str)  # 특수문자 제거\n",
        "    predictions.append(clean_pred_label)\n",
        "\n",
        "# 새로운 열에 예측값 추가\n",
        "test_df['predicted_label'] = predictions\n",
        "\n",
        "# 실제 라벨과 예측 라벨을 _로 분리하여 다중 라벨로 변환\n",
        "mlb = MultiLabelBinarizer()\n",
        "actual_labels_binary = mlb.fit_transform([label.split('_') for label in test_df['category']])\n",
        "predictions_binary = mlb.transform([label.split('_') for label in test_df['predicted_label']])\n",
        "\n",
        "# 정확도 측정\n",
        "accuracy = accuracy_score(actual_labels_binary, predictions_binary)\n",
        "\n",
        "# Precision, Recall, F1-score 계산\n",
        "precision = precision_score(actual_labels_binary, predictions_binary, average='micro')\n",
        "recall = recall_score(actual_labels_binary, predictions_binary, average='micro')\n",
        "f1 = f1_score(actual_labels_binary, predictions_binary, average='micro')\n",
        "\n",
        "print(\"======================================\")\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Overall Precision: {precision:.4f}')\n",
        "print(f'Overall Recall: {recall:.4f}')\n",
        "print(f'Overall F1-score: {f1:.4f}')\n",
        "print(\"======================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3FIMWnw69Dd",
        "outputId": "bdb43874-8c47-4672-d113-b8aa9e49f479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:900: UserWarning: unknown class(es) ['주방', '팔찌/목걸이'] will be ignored\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================\n",
            "Accuracy: 0.7814\n",
            "Overall Precision: 0.9176\n",
            "Overall Recall: 0.9172\n",
            "Overall F1-score: 0.9174\n",
            "======================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "Ap56SofeExBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2단계: 문장 임베딩을 위한 함수 정의\n",
        "def get_sentence_embedding(sentence):\n",
        "    words = sentence.split()\n",
        "    embeddings = [model.get_word_vector(word) for word in words]\n",
        "    return np.mean(embeddings, axis=0)\n",
        "\n",
        "# LSTM 모델 정의\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        out = self.fc(lstm_out[:, -1, :])  # 마지막 타임 스탭의 출력 사용\n",
        "        return out"
      ],
      "metadata": {
        "id": "yWpA2o50Eli9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3단계: 데이터셋 클래스 정의\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, sentences, labels):\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.sentences[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "ule33qH5Eoxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드 및 처리\n",
        "def load_data(file_path):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            label, text = line.split(\"\\t\", 1)  # Assuming the format is __label__category text\n",
        "            sentences.append(text.strip())\n",
        "            labels.append(label)\n",
        "    return sentences, labels"
      ],
      "metadata": {
        "id": "nNe1t9PeE17l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "train_sentences, train_labels = load_data('/content/drive/MyDrive/Colab Notebooks/item_category_classification/product_category_from_fullset_train_cleaned_filtered_tokenized.tsv')\n",
        "test_sentences, test_labels = load_data('/content/drive/MyDrive/Colab Notebooks/item_category_classification/product_category_from_fullset_test_cleaned_filtered_tokenized.tsv')"
      ],
      "metadata": {
        "id": "-Tkoh2vZFOYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 임베딩 생성\n",
        "train_embeddings = np.array([get_sentence_embedding(sentence) for sentence in train_sentences])\n",
        "test_embeddings = np.array([get_sentence_embedding(sentence) for sentence in test_sentences])"
      ],
      "metadata": {
        "id": "x5tkmCSzFyhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨을 정수로 변환\n",
        "label_to_index = {label: idx for idx, label in enumerate(set(train_labels))}\n",
        "\n",
        "# test_labels에서 train_labels에 없는 라벨 추가\n",
        "for label in set(test_labels):\n",
        "    if label not in label_to_index:\n",
        "        # 새로운 라벨에 대한 인덱스 추가\n",
        "        label_to_index[label] = len(label_to_index)\n",
        "\n",
        "# 인덱싱\n",
        "train_labels_indexed = [label_to_index[label] for label in train_labels]\n",
        "test_labels_indexed = [label_to_index[label] for label in test_labels]\n"
      ],
      "metadata": {
        "id": "EB7CEKm8GkQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM 하이퍼파라미터 설정\n",
        "input_size = train_embeddings.shape[1]  # fastText 임베딩 차원\n",
        "hidden_size = 128\n",
        "output_size = len(label_to_index)  # 클래스 수\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "WT1kH99ZHAMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM 모델 초기화\n",
        "lstm_model = LSTMClassifier(input_size, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "lH4Rq4PQHRpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋과 데이터로더 생성\n",
        "train_dataset = TextDataset(train_embeddings, train_labels_indexed)\n",
        "test_dataset = TextDataset(test_embeddings, test_labels_indexed)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "nneike4hHTeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4단계: LSTM 모델 학습\n",
        "lstm_model.train()\n",
        "for epoch in range(10):  # 예시로 10 에폭\n",
        "    total_loss = 0\n",
        "    for sentences, labels in tqdm(train_loader):\n",
        "        # 텐서로 변환\n",
        "        sentences_tensor = torch.tensor(sentences, dtype=torch.float32).unsqueeze(1)  # (batch_size, sequence_length, input_size)\n",
        "        labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = lstm_model(sentences_tensor)  # LSTM 모델에 입력\n",
        "        loss = criterion(outputs, labels_tensor)  # 손실 계산\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/10], Loss: {total_loss / len(train_loader):.4f}')\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtanUjmAHVvO",
        "outputId": "2cc45a6b-c99d-4b34-f692-f4fa33305131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10788 [00:00<?, ?it/s]<ipython-input-55-f9b393df14c8>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  sentences_tensor = torch.tensor(sentences, dtype=torch.float32).unsqueeze(1)  # (batch_size, sequence_length, input_size)\n",
            "<ipython-input-55-f9b393df14c8>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
            "100%|██████████| 10788/10788 [00:43<00:00, 247.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.0313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10788/10788 [00:44<00:00, 243.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.7416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10788/10788 [00:42<00:00, 252.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.6993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10788/10788 [00:42<00:00, 252.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.6740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10788/10788 [00:42<00:00, 255.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.6558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10788/10788 [00:41<00:00, 258.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.6414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10788/10788 [00:41<00:00, 261.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.6293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10788/10788 [00:41<00:00, 257.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.6192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10788/10788 [00:43<00:00, 248.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.6102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10788/10788 [00:42<00:00, 254.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.6020\n",
            "Training complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5단계: 모델 평가\n",
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()  # 평가 모드\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sentences, labels in data_loader:\n",
        "            sentences_tensor = torch.tensor(sentences, dtype=torch.float32).unsqueeze(1)\n",
        "            labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "            outputs = model(sentences_tensor)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels_tensor.size(0)\n",
        "            correct += (predicted == labels_tensor).sum().item()\n",
        "\n",
        "            all_labels.extend(labels_tensor.numpy())\n",
        "            all_predictions.extend(predicted.numpy())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy, all_labels, all_predictions\n",
        "\n",
        "# 평가\n",
        "accuracy, true_labels, predicted_labels = evaluate_model(lstm_model, test_loader)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHfJMazzIzLl",
        "outputId": "467bde36-bce5-40bf-b5ce-a334fdf78c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-a30b29ca1ded>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  sentences_tensor = torch.tensor(sentences, dtype=torch.float32).unsqueeze(1)\n",
            "<ipython-input-56-a30b29ca1ded>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels_tensor = torch.tensor(labels, dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "from tokenizers import normalizers\n",
        "from tokenizers.normalizers import NFKC"
      ],
      "metadata": {
        "id": "zHYOx_jsJwqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. BPE 토크나이저 생성\n",
        "tokenizer = Tokenizer(BPE())\n",
        "tokenizer.normalizer = normalizers.Sequence([NFKC()])\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "# 2. BPE 트레이너 설정\n",
        "trainer = BpeTrainer(special_tokens=[\"<unk>\"], vocab_size=30000)\n",
        "\n",
        "# 3. 학습 데이터로 BPE 학습\n",
        "file = '/content/drive/MyDrive/Colab Notebooks/item_category_classification/complete_filtered.txt'  # 학습 데이터 파일 경로 리스트\n",
        "tokenizer.train([file], trainer)\n",
        "\n",
        "# 4. 토큰화 함수 정의\n",
        "def bpe_tokenize(text):\n",
        "    # BPE 토크나이징 수행\n",
        "    output = tokenizer.encode(text)\n",
        "    # 공백으로 구분된 토큰을 반환\n",
        "    return ' '.join(output.tokens)"
      ],
      "metadata": {
        "id": "X4CWTPSaJxY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F  # Import the functional API for softmax\n",
        "\n",
        "# 6단계: 입력 문자열로 라벨 예측 및 확률 반환\n",
        "def predict(input_string, model, tokenizer, label_to_index):\n",
        "    # BPE 토크나이징\n",
        "    tokens = bpe_tokenize(input_string)\n",
        "\n",
        "    # 문장 임베딩 생성\n",
        "    input_embedding = get_sentence_embedding(tokens)\n",
        "\n",
        "    # 텐서로 변환\n",
        "    input_tensor = torch.tensor(input_embedding, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # (1, 1, input_size)\n",
        "\n",
        "    # 모델 예측\n",
        "    model.eval()  # 평가 모드\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        probabilities = F.softmax(output, dim=1)  # 소프트맥스 적용\n",
        "        predicted_label_index = torch.max(probabilities, 1)[1]\n",
        "\n",
        "    # 인덱스를 라벨로 변환\n",
        "    predicted_label = [key for key, value in label_to_index.items() if value == predicted_label_index.item()]\n",
        "    predicted_probability = probabilities[0][predicted_label_index.item()].item()  # 예측 확률\n",
        "\n",
        "    return predicted_label[0].replace(\"__label__\", \"\") if predicted_label else None, predicted_probability  # 예측된 라벨과 확률 반환\n"
      ],
      "metadata": {
        "id": "RI8CP6HcLpXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시: 입력 문자열로 예측 수행\n",
        "input_string = \"앙고라오버핏가디건\"  # 입력 문자열을 여기에 작성\n",
        "predicted_label, predicted_probability = predict(input_string, lstm_model, tokenizer, label_to_index)\n",
        "print(f'Predicted Label: {predicted_label}, Probability: {predicted_probability:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rDHs64dL8lQ",
        "outputId": "b71cf143-e5e9-49ba-c0ec-62ade296707e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: 의류_여성아우터_가디건, Probability: 0.4975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58aDS2M7MGjA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}